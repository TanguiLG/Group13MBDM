{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05ae8a2b",
   "metadata": {},
   "source": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "test",
   "id": "90c5b215ff9a2e58"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ema_workbench import (\n",
    "    Policy,\n",
    "    ema_logging,\n",
    "    MultiprocessingEvaluator,\n",
    ")\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "# choose problem formulation number, between 0-5\n",
    "# each problem formulation has its own list of outcomes\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(3)\n",
    "\n",
    "import copy\n",
    "\n",
    "for unc in dike_model.uncertainties:\n",
    "    print(repr(unc))\n",
    "\n",
    "uncertainties = copy.deepcopy(dike_model.uncertainties)\n",
    "# enlisting policy levers, their types (RealParameter/IntegerParameter), lower boundary, and upper boundary\n",
    "for policy in dike_model.levers:\n",
    "    print(repr(policy))\n",
    "\n",
    "levers = copy.deepcopy(dike_model.levers)\n",
    "# enlisting outcomes\n",
    "for outcome in dike_model.outcomes:\n",
    "    print(repr(outcome))\n",
    "\n",
    "def get_do_nothing_dict():\n",
    "    return {l.name: 0 for l in dike_model.levers}\n",
    "\n",
    "\n",
    "policies = [\n",
    "    Policy(\n",
    "        \"policy 1\",\n",
    "        **dict(\n",
    "            get_do_nothing_dict(),\n",
    "            **{\"0_RfR 0\": 1, \"0_RfR 1\": 1, \"0_RfR 2\": 1, \"A.1_DikeIncrease 0\": 5}\n",
    "        )\n",
    "    ),\n",
    "    Policy(\n",
    "        \"policy 2\",\n",
    "        **dict(\n",
    "            get_do_nothing_dict(),\n",
    "            **{\"4_RfR 0\": 1, \"4_RfR 1\": 1, \"4_RfR 2\": 1, \"A.5_DikeIncrease 0\": 5}\n",
    "        )\n",
    "    ),\n",
    "    Policy(\n",
    "        \"policy 3\",\n",
    "        **dict(\n",
    "            get_do_nothing_dict(),\n",
    "            **{\"1_RfR 0\": 1, \"2_RfR 1\": 1, \"3_RfR 2\": 1, \"A.3_DikeIncrease 0\": 5}\n",
    "        )\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd45245",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_scenarios = 100\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results = evaluator.perform_experiments(n_scenarios, policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc736a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "# conditional on y\n",
    "all_data = pd.DataFrame({k:v for k,v in outcomes.items()})\n",
    "\n",
    "# let's get the unique indices for the minima and maxima across \n",
    "# all objectives\n",
    "indices = pd.concat([all_data.idxmax(), all_data.idxmin()]).unique()\n",
    "\n",
    "limits = parcoords.get_limits(all_data)\n",
    "axes = parcoords.ParallelAxes(limits)\n",
    "\n",
    "# we set the linewidth lower, and make the lines slightly transpartant using alpha\n",
    "# this often helps reveal patterns in the results.\n",
    "axes.plot(all_data, color='lightgrey', lw=0.5, alpha=0.5)\n",
    "axes.plot(all_data.iloc[indices, :], color=sns.color_palette()[0], lw=1)\n",
    "#axes.invert_axis('max_P')\n",
    "\n",
    "fig = plt.gcf()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02edc034",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data.idxmax())\n",
    "print(all_data.idxmin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2a7ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also all we need are the uncertainty columns\n",
    "selected = experiments.loc[[184,124], ['A.1_pfail', 'A.1_Bmax', 'A.1_Brate', 'A.2_pfail', 'A.2_Bmax', 'A.2_Brate','A.3_pfail', 'A.3_Bmax', 'A.3_Brate','A.4_pfail', 'A.4_Bmax', 'A.4_Brate','A.5_pfail', 'A.5_Bmax', 'A.5_Brate', 'discount rate 0','discount rate 1','discount rate 2','A.0_ID flood wave shape']]\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f9e8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import Scenario\n",
    "\n",
    "scenarios = [Scenario(f\"{index}\", **row) for index, row in selected.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c8c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import MultiprocessingEvaluator, ema_logging\n",
    "\n",
    "from ema_workbench.em_framework.optimization import (ArchiveLogger,\n",
    "                                                     EpsilonProgress,\n",
    "                                                     to_problem, epsilon_nondominated)\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "from ema_workbench.em_framework import optimization\n",
    "\n",
    "def transform_variables_fixed(problem, variables):\n",
    "    converted_vars = []\n",
    "    for type, var in zip(problem.types, variables):\n",
    "        if isinstance(var, (list, tuple)):\n",
    "            var = type.decode(var)\n",
    "            try:\n",
    "                var = var[0]\n",
    "            except TypeError:\n",
    "                pass\n",
    "        converted_vars.append(var)\n",
    "    return converted_vars\n",
    "from ema_workbench.em_framework import optimization\n",
    "from ema_workbench.util.ema_exceptions import EMAError\n",
    "from platypus import Solution\n",
    "\n",
    "def rebuild_platypus_population_fixed(archive, problem):\n",
    "    solutions = []\n",
    "\n",
    "    for _, row in archive.iterrows():\n",
    "        try:\n",
    "            decision_variables = [row[attr] for attr in problem.parameter_names]\n",
    "        except KeyError:\n",
    "            missing_parameters = [attr for attr in problem.parameter_names if attr not in row]\n",
    "            raise EMAError(f\"Parameter names {missing_parameters} not found in archive\")\n",
    "\n",
    "        try:\n",
    "            objectives = [row[attr] for attr in problem.outcome_names]\n",
    "        except KeyError:\n",
    "            missing_outcomes = [attr for attr in problem.outcome_names if attr not in row]\n",
    "            raise EMAError(f\"Outcome names {missing_outcomes} not found in archive\")\n",
    "\n",
    "        solution = Solution(problem)\n",
    "\n",
    "        # âœ… the clean, warning-free way:\n",
    "        solution.variables[:] = decision_variables\n",
    "        solution.objectives[:] = objectives\n",
    "\n",
    "        solutions.append(solution)\n",
    "\n",
    "    return solutions\n",
    "\n",
    "# Monkeypatch the function\n",
    "optimization.rebuild_platypus_population = rebuild_platypus_population_fixed\n",
    "optimization.transform_variables = transform_variables_fixed\n",
    "def optimize(scenario, nfe, model, epsilons):\n",
    "    results = []\n",
    "    convergences = []\n",
    "    problem = to_problem(model, searchover=\"levers\")\n",
    "\n",
    "    with MultiprocessingEvaluator(model) as evaluator:\n",
    "        for i in range(5):\n",
    "            convergence_metrics = [\n",
    "                ArchiveLogger(\n",
    "                    \"./archives\",\n",
    "                    [l.name for l in model.levers],\n",
    "                    [o.name for o in model.outcomes],\n",
    "                    base_filename=f\"assignment_final_{scenario.name}_seed_{i}.tar.gz\",\n",
    "                ),\n",
    "                EpsilonProgress(),\n",
    "            ]\n",
    "\n",
    "            result, convergence = evaluator.optimize(nfe=nfe, searchover='levers',\n",
    "                                         convergence=convergence_metrics,\n",
    "                                         epsilons=epsilons,\n",
    "                                         reference=scenario)\n",
    "\n",
    "            results.append(result)\n",
    "            convergences.append(convergence)\n",
    "    \n",
    "    # merge the results using a non-dominated sort  \n",
    "    reference_set = epsilon_nondominated(results, epsilons, problem)\n",
    "    \n",
    "    return reference_set, convergences\n",
    "\n",
    "\n",
    "results = []\n",
    "for scenario in scenarios:\n",
    "    epsilons = [0.1,]*len(dike_model.outcomes)\n",
    "    \n",
    "    # note that 100000 nfe is again rather low to ensure proper convergence\n",
    "    results.append(optimize(scenario, 1e2, dike_model, epsilons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1876a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platypus import Hypervolume\n",
    "from ema_workbench.em_framework.optimization import rebuild_platypus_population\n",
    "\n",
    "\n",
    "def calculate_convergence_metrics(problem, archives_file):\n",
    "    #hv = Hypervolume(minimum=[0, 0, 0, 0], maximum=[12, 3, 1, 1])\n",
    "    hv = Hypervolume(\n",
    "    minimum=[0] * problem.nobjs,\n",
    "    maximum=[2000] * problem.nobjs)\n",
    "    archives = ArchiveLogger.load_archives(archives_file)\n",
    "    metrics = []\n",
    "    for nfe, archive in archives.items():\n",
    "        population = rebuild_platypus_population(archive, problem)\n",
    "        metrics.append(dict(hypervolume=hv.calculate(population), nfe=nfe))\n",
    "        \n",
    "    metrics = pd.DataFrame.from_dict(metrics)\n",
    "    metrics.sort_values(by=\"nfe\", inplace=True, ignore_index=True)    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "problem = to_problem(dike_model, searchover=\"levers\")\n",
    "convergence_calculations = []\n",
    "for (refset, eps_progress), scenario in zip(results, scenarios):\n",
    "    for seed, seed_eps in zip(range(5), eps_progress):\n",
    "        archive_file = f\"./archives/assignment_final_{scenario.name}_seed_{seed}.tar.gz\"\n",
    "        metrics = calculate_convergence_metrics(problem, archive_file)\n",
    "        metrics[\"seed\"] = seed\n",
    "        metrics[\"scenario\"] = scenario.name\n",
    "        metrics[\"epsilon_progress\"] = seed_eps.epsilon_progress   \n",
    "        \n",
    "        convergence_calculations.append(metrics)\n",
    "convergence = pd.concat(convergence_calculations, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9d1aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2)\n",
    "\n",
    "colors = sns.color_palette()\n",
    "\n",
    "legend_items = []\n",
    "for (scenario_name, scores), color in zip(convergence.groupby(\"scenario\"), colors):\n",
    "    # we use this for a custom legend\n",
    "    legend_items.append((mpl.lines.Line2D([0, 0], [1, 1], c=color), scenario_name))\n",
    "    for seed, score in scores.groupby(\"seed\"):\n",
    "        ax1.plot(score.nfe, score.hypervolume, c=color, lw=1)\n",
    "        ax2.plot(score.nfe, score.epsilon_progress, c=color, lw=1)\n",
    "\n",
    "\n",
    "ax1.set_ylabel('hypervolume')\n",
    "ax1.set_xlabel('nfe')\n",
    "ax2.set_ylabel('$\\epsilon$ progress')\n",
    "ax2.set_xlabel('nfe')\n",
    "\n",
    "# create our custom legend\n",
    "artists, labels = zip(*legend_items)\n",
    "fig.legend(artists, labels, bbox_to_anchor=(1,0.9))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab9a1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import Policy\n",
    "\n",
    "policies = []\n",
    "for i, (result, _) in enumerate(results):\n",
    "    result = result.iloc[:, 0:31]\n",
    "    for j, row in result.iterrows():\n",
    "        policy = Policy(f'scenario {i} option {j}', **row.to_dict())\n",
    "        policies.append(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a09d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    reeevaluation_results = evaluator.perform_experiments(2, policies=policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99359ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = reeevaluation_results\n",
    "\n",
    "# setup a dataframe for the outcomes\n",
    "# we add scenario and policy as additional columns\n",
    "# we need scenario because regret is calculated on a scenario by scenario basis\n",
    "# we add policy because we need to get the maximum regret for each policy.\n",
    "outcomes = pd.DataFrame(outcomes)\n",
    "outcomes['scenario'] = experiments.scenario\n",
    "outcomes['policy'] = experiments.policy\n",
    "\n",
    "def calculate_regret(x):\n",
    "    best = x.min(numeric_only=True)\n",
    "    regret = x.loc[:, best.index] - best\n",
    "    regret['policy'] = x.policy\n",
    "    return regret\n",
    "\n",
    "\n",
    "# we want to calculate regret on a scenario by scenario basis\n",
    "regret = outcomes.groupby('scenario', group_keys=False).apply(calculate_regret)\n",
    "\n",
    "# as last step, we calculate the maximum regret for each policy\n",
    "max_regret = regret.groupby('policy').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eac8327",
   "metadata": {},
   "outputs": [],
   "source": [
    "limits = parcoords.get_limits(max_regret)\n",
    "paraxes = parcoords.ParallelAxes(max_regret)\n",
    "paraxes.plot(max_regret, lw=1, alpha=0.75)\n",
    "\n",
    "# let's resize the figure a bit\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 4)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
